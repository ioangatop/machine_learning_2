{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29b72b5f8cb2ce33aa81c939b8d2138c",
     "grade": false,
     "grade_id": "cell-02487845739eb4fd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Lab 3: Expectation Maximization and Variational Autoencoder\n",
    "\n",
    "### Machine Learning 2 (2019)\n",
    "\n",
    "* The lab exercises can be done in groups of two people, or individually.\n",
    "* The deadline is Tuesday, October 15th at 17:00.\n",
    "* Assignment should be submitted through Canvas! Make sure to include your and your teammates' names with the submission.\n",
    "* Attach the .IPYNB (IPython Notebook) file containing your code and answers. Naming of the file should be \"studentid1\\_studentid2\\_lab#\", for example, the attached file should be \"12345\\_12346\\_lab1.ipynb\". Only use underscores (\"\\_\") to connect ids, otherwise the files cannot be parsed.\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in an IPython Notebook: http://ipython.org/notebook.html. If you have problems, please ask.\n",
    "* Use __one cell__ for code and markdown answers only!\n",
    "    * Put all code in the cell with the ```# YOUR CODE HERE``` comment and overwrite the ```raise NotImplementedError()``` line.\n",
    "    * For theoretical questions, put your solution using LaTeX style formatting in the YOUR ANSWER HERE cell.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* Large parts of you notebook will be graded automatically. Therefore it is important that your notebook can be run completely without errors and within a reasonable time limit. To test your notebook before submission, select Kernel -> Restart \\& Run All.\n",
    "$\\newcommand{\\bx}{\\mathbf{x}} \\newcommand{\\bpi}{\\mathbf{\\pi}} \\newcommand{\\bmu}{\\mathbf{\\mu}} \\newcommand{\\bX}{\\mathbf{X}} \\newcommand{\\bZ}{\\mathbf{Z}} \\newcommand{\\bz}{\\mathbf{z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4e05229ee79b55d6589e1ea8de68f32",
     "grade": false,
     "grade_id": "cell-a0a6fdb7ca694bee",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Installing PyTorch\n",
    "\n",
    "In this lab we will use PyTorch. PyTorch is an open source deep learning framework primarily developed by Facebook's artificial-intelligence research group. In order to install PyTorch in your conda environment go to https://pytorch.org and select your operating system, conda, Python 3.6, no cuda. Copy the text from the \"Run this command:\" box. Now open a terminal and activate your 'ml2labs' conda environment. Paste the text and run. After the installation is done you should restart Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9c3d77f550b5fd93b34fd18825c47f0",
     "grade": false,
     "grade_id": "cell-746cac8d9a21943b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### MNIST data\n",
    "\n",
    "In this Lab we will use several methods for unsupervised learning on the MNIST dataset of written digits. The dataset contains digital images of handwritten numbers $0$ through $9$. Each image has 28x28 pixels that each take 256 values in a range from white ($= 0$) to  black ($=1$). The labels belonging to the images are also included. \n",
    "Fortunately, PyTorch comes with a MNIST data loader. The first time you run the box below it will download the MNIST data set. That can take a couple of minutes.\n",
    "The main data types in PyTorch are tensors. For Part 1, we will convert those tensors to numpy arrays. In Part 2, we will use the torch module to directly work with PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fbc152afa1255331d7b88bf00b7156c",
     "grade": false,
     "grade_id": "cell-7c995be0fda080c0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johngatopoulos/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/johngatopoulos/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "train_labels = train_dataset.train_labels.numpy()\n",
    "train_data = train_dataset.train_data.numpy()\n",
    "# For EM we will use flattened data\n",
    "train_data = train_data.reshape(train_data.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fc852f9bfb0bab10d4c23eada309e89",
     "grade": false,
     "grade_id": "cell-8b4a44df532b1867",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Expectation Maximization\n",
    "We will use the Expectation Maximization (EM) algorithm for the recognition of handwritten digits in the MNIST dataset. The images are modelled as a Bernoulli mixture model (see Bishop $\\S9.3.3$):\n",
    "$$\n",
    "p(\\bx|\\bmu, \\bpi) = \\sum_{k=1}^K  \\pi_k \\prod_{i=1}^D \\mu_{ki}^{x_i}(1-\\mu_{ki})^{(1-x_i)}\n",
    "$$\n",
    "where $x_i$ is the value of pixel $i$ in an image, $\\mu_{ki}$ represents the probability that pixel $i$ in class $k$ is black, and $\\{\\pi_1, \\ldots, \\pi_K\\}$ are the mixing coefficients of classes in the data. We want to use this data set to classify new images of handwritten numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54064637b7e7cf938c0f778d748a226a",
     "grade": false,
     "grade_id": "cell-af03fef663aa85b2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Binary data (5 points)\n",
    "As we like to apply our Bernoulli mixture model, write a function `binarize` to convert the (flattened) MNIST data to binary images, where each pixel $x_i \\in \\{0,1\\}$, by thresholding at an appropriate level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe8607a4d734f7f26ef1ee1e54b33471",
     "grade": false,
     "grade_id": "cell-ec4365531ca57ef3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def binarize(X):\n",
    "    # YOUR CODE HERE\n",
    "    return 1. * (X >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "231b2c9f29bc5c536c60cef4d74793a1",
     "grade": true,
     "grade_id": "cell-2f16f57cb68a83b3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test test test!\n",
    "bin_train_data = binarize(train_data)\n",
    "assert bin_train_data.dtype == np.float\n",
    "assert bin_train_data.shape == train_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0a39404cc2f67078b399ee34653a3ac",
     "grade": false,
     "grade_id": "cell-462e747685e8670f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Sample a few images of digits $2$, $3$ and $4$; and show both the original and the binarized image together with their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f3c981f0fda5ba3bdfcefb9144305c7",
     "grade": true,
     "grade_id": "cell-784c6bd177a9aa42",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def visualize_digit(digit, n_samples=4):\n",
    "    idxs = np.where(train_labels == digit)[0][:n_samples]\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2*n_samples, figsize=(20, 20))\n",
    "\n",
    "    i=0\n",
    "    for idx in idxs:\n",
    "        img = train_data[idx].reshape(28, 28)\n",
    "        bin_img = binarize(img)\n",
    "        ax[i].imshow(img, cmap='gray')\n",
    "        ax[i].set_title(str(digit), fontsize=16)\n",
    "        ax[i].axis('off')\n",
    "        ax[i+1].imshow(bin_img, cmap='gray')\n",
    "        ax[i+1].set_title('Binarized '+str(digit), fontsize=16)\n",
    "        ax[i+1].axis('off')\n",
    "        i+=2\n",
    "    \n",
    "for digits in [2, 3, 4]:\n",
    "    visualize_digit(digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b9da574d24193df76e96ed8ca62c7b0",
     "grade": false,
     "grade_id": "cell-56b33654497d4052",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Implementation (40 points)\n",
    "You are going to write a function ```EM(X, K, max_iter)``` that implements the EM algorithm on the Bernoulli mixture model. \n",
    "\n",
    "The only parameters the function has are:\n",
    "* ```X``` :: (NxD) array of input training images\n",
    "* ```K``` :: size of the latent space\n",
    "* ```max_iter``` :: maximum number of iterations, i.e. one E-step and one M-step\n",
    "\n",
    "You are free to specify your return statement.\n",
    "\n",
    "Make sure you use a sensible way of terminating the iteration process early to prevent unnecessarily running through all epochs. Vectorize computations using ```numpy``` as  much as possible.\n",
    "\n",
    "You should implement the `E_step(X, mu, pi)` and `M_step(X, gamma)` separately in the functions defined below. These you can then use in your function `EM(X, K, max_iter)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "316c9131692747c363b5db8e9091d362",
     "grade": false,
     "grade_id": "cell-882b13c117a73cc4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def E_step(X, mu, pi):\n",
    "    # YOUR CODE HERE\n",
    "    eps = 1e-10 # for stability in log operations\n",
    "    gamma = np.exp(np.log(pi+eps) + X @ np.log(mu.T+eps) + (1 - X) @ np.log(1 - mu.T + eps))    \n",
    "    gamma  /= gamma.sum(axis=1)[:, np.newaxis]\n",
    "    return gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1418f4014e98024fc97446ce27766c1d",
     "grade": true,
     "grade_id": "cell-f7c7dd52d82e2498",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's test on 5 datapoints\n",
    "n_test = 5\n",
    "X_test = bin_train_data[:n_test]\n",
    "D_test, K_test = X_test.shape[1], 10\n",
    "\n",
    "np.random.seed(2018)\n",
    "mu_test = np.random.uniform(low=.25, high=.75, size=(K_test,D_test))\n",
    "pi_test = np.ones(K_test) / K_test\n",
    "\n",
    "gamma_test = E_step(X_test, mu_test, pi_test)\n",
    "assert gamma_test.shape == (n_test, K_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c426a613653174795cd9c8327ab6e20",
     "grade": false,
     "grade_id": "cell-f1b11b8765bd1ef6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def M_step(X, gamma):\n",
    "    # YOUR CODE HERE\n",
    "    N_m = gamma.sum(axis=0)\n",
    "    pi = N_m / X.shape[0]\n",
    "    mu = gamma.T @ X / N_m[:, np.newaxis]\n",
    "    return mu, pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f60d48b8b22063cef560b42944a0aa4",
     "grade": true,
     "grade_id": "cell-6e7c751b30acfd45",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Oh, let's test again\n",
    "mu_test, pi_test = M_step(X_test, gamma_test)\n",
    "\n",
    "assert mu_test.shape == (K_test,D_test)\n",
    "assert pi_test.shape == (K_test, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acfec6384b058cb0ce1932006fbfebc4",
     "grade": true,
     "grade_id": "cell-d6c4368246dee7e6",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def EM(X, K, max_iter, threshold=1e-5, mu=None, pi=None):\n",
    "    # YOUR CODE HERE\n",
    "    mu = np.random.uniform(low=.15, high=.85, size=(K, shape(X)[1]))\n",
    "    pi = np.ones(K) / K\n",
    "\n",
    "    for i in range(1, max_iter+1):\n",
    "        mu_old, pi_old = mu, pi\n",
    "\n",
    "        gamma = E_step(X, mu, pi)\n",
    "        mu, pi = M_step(X, gamma) \n",
    "\n",
    "        delta_mu, delta_pi = np.linalg.norm(mu-mu_old), np.linalg.norm(pi-pi_old)\n",
    "        if i%10 == 0:\n",
    "            print('Epoch [{:4d}/{:4d}] | delta mu: {:6.6f} | delta pi: {:6.6f}'.format(\n",
    "                i, max_iter, delta_mu, delta_pi))\n",
    "\n",
    "        if delta_mu < threshold and delta_pi < threshold:\n",
    "            print(\"\\nConverged at iteration {}.\".format(i))\n",
    "            return gamma, mu, pi        \n",
    "\n",
    "    return gamma, mu, pi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4fc12faa0da660f7a4d9cc7deb41b25",
     "grade": false,
     "grade_id": "cell-e1077ed3b83489be",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.3 Three digits experiment (10 points)\n",
    "In analogue with Bishop $\\S9.3.3$, sample a training set consisting of only __binary__ images of written digits $2$, $3$, and $4$. Run your EM algorithm and show the reconstructed digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdbce0fad0ed151063d4c489ce999e3e",
     "grade": true,
     "grade_id": "cell-477155d0264d7259",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True mixing coefficients: [0.33227372 0.34192181 0.32580447]\n",
      "\n",
      "Training Progress\n",
      "Epoch [  10/ 100] | delta mu: 0.153841 | delta pi: 0.011909\n",
      "Epoch [  20/ 100] | delta mu: 0.002538 | delta pi: 0.000212\n",
      "Epoch [  30/ 100] | delta mu: 0.000043 | delta pi: 0.000003\n",
      "\n",
      "Converged at iteration 34.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def sample_labels(labels, epochs=100, K=None):\n",
    "    if K is None: K = len(labels)\n",
    "    labels_idxs = np.isin(train_labels, labels)\n",
    "    subset_train_labels = train_labels[labels_idxs]\n",
    "    subset_train_data = bin_train_data[labels_idxs]\n",
    "\n",
    "    pi_true = []\n",
    "    for label in labels:\n",
    "        n_labels = np.isin(train_labels, label)\n",
    "        pi_true.append(n_labels.sum())\n",
    "    print('True mixing coefficients: {}'.format(np.array(pi_true)/np.array(pi_true).sum()))\n",
    "\n",
    "    print('\\nTraining Progress')\n",
    "    gamma, mu, pi = EM(subset_train_data, K, epochs)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=K, figsize=(15, 15), dpi=100)\n",
    "    for i in range(K):\n",
    "        ax[i].imshow(mu[i].reshape(28,28), cmap='gray')\n",
    "        ax[i].set_title('Parameters class: {}\\n pi = {:0.3f}'.format(i, pi[i]), fontsize=K**(-1)//0.02)\n",
    "        ax[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_labels([2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "485543f4893938d2a9dc1c17d8221cbc",
     "grade": false,
     "grade_id": "cell-88c9664f995b1909",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Can you identify which element in the latent space corresponds to which digit? What are the identified mixing coefficients for digits $2$, $3$ and $4$, and how do these compare to the true ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae7b5acea6089e2590059f90b0d0a0be",
     "grade": true,
     "grade_id": "cell-3680ae2159c48193",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "#### YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "Looking at the results, we can clearly seperate the distinguish the digits between the elements in the latent space. They illustrated as 'gost' digits, which is expected, as we plot the mean distribution of every latent space.\n",
    "\n",
    "Moreover, the mixing coefficients (appeared in the second row of the title of every class figure), follow a uniform distribution, imitating the original one, since it appears that we train our model on a balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98e04feb59a36867367b3027df9e226d",
     "grade": false,
     "grade_id": "cell-0891dda1c3e80e9a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.4 Experiments (20 points)\n",
    "Perform the follow-up experiments listed below using your implementation of the EM algorithm. For each of these, describe/comment on the obtained results and give an explanation. You may still use your dataset with only digits 2, 3 and 4 as otherwise computations can take very long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "439067186fa3ef1d7261a9bcf5a84ea6",
     "grade": false,
     "grade_id": "cell-06fe1b1355689928",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.1 Size of the latent space (5 points)\n",
    "Run EM with $K$ larger or smaller than the true number of classes. Describe your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "791512aeadd30c4b586b966ca10e6fad",
     "grade": true,
     "grade_id": "cell-6c9057f2546b7215",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "EM on labels 2, 3 and 4 and K = 5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "True mixing coefficients: [0.33227372 0.34192181 0.32580447]\n",
      "\n",
      "Training Progress\n",
      "Epoch [  10/ 100] | delta mu: 0.597703 | delta pi: 0.016363\n",
      "Epoch [  20/ 100] | delta mu: 0.052774 | delta pi: 0.001723\n",
      "Epoch [  30/ 100] | delta mu: 0.011879 | delta pi: 0.000363\n",
      "Epoch [  40/ 100] | delta mu: 0.022871 | delta pi: 0.000739\n",
      "Epoch [  50/ 100] | delta mu: 0.018087 | delta pi: 0.000317\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print('-'*70+'\\nEM on labels 2, 3 and 4 and K = 5\\n'+'-'*70+'\\n')\n",
    "sample_labels(labels=[2, 3, 4], K=7)\n",
    "\n",
    "print('-'*70+'\\nEM on labels 2, 3 and 4 and K = 2\\n'+'-'*70+'\\n')\n",
    "sample_labels(labels=[2, 3, 4], K=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e12e40c2d2165e3bb500b5504128910d",
     "grade": true,
     "grade_id": "cell-f01c37653160244b",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "#### YOUR ANSWER HERE\n",
    "\n",
    "When we use a bigger numeber of class, the EM seems to further distinguishes the digits accoring to their variations. For example, it classifies differently the digits `2` where their bottom part is rounded from the standard one. Anothere case it the digit `4`, where it distinguishes thouse who are skewing to the left from all the others.\n",
    "\n",
    "When we run the experiment with a lower number of class, specifically for `K = 2`, we observed that the digit `4` always make it as a seperate class, and the two others are merged. As the EM seems `2` and `3` closser (similarity) than any combination of the previous with `4`, it makes the algorithm treat `2` as a special case of `3` and it desides to merge them together into one class. Intuitively, one can arguee that the digit `3` is dominand over the `2`, as one can see the `3` cover a big area of `2`.\n",
    "This can also be justified by the mixing coefficients of the latend space, as the class where `4` is visible has half the probability than the other (~ 0.35 and 0.65 = 2*0.325). Finally, on the class that `4` is not visible, we can see that shape is the digit `3`, with a more washed-out connected line from the middle part to the bottom, which is the part of `2` which makes it different from the former."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b306681523a2e35eea310ac10bb68999",
     "grade": false,
     "grade_id": "cell-cf478d67239b7f2e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.2 Identify misclassifications (10 points)\n",
    "How can you use the data labels to assign a label to each of the clusters/latent variables? Use this to identify images that are 'misclassified' and try to understand why they are. Report your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "000c11bd8756a4e24296c7c55d3ee17e",
     "grade": true,
     "grade_id": "cell-daa1a492fbba5c7e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "baf43434481c13d76ad51e3ba07e2bf5",
     "grade": true,
     "grade_id": "cell-329245c02df7850d",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "#### YOUR ANSWER HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "640bc57a2d08c3becf534bb5e4b35971",
     "grade": false,
     "grade_id": "cell-67ce1222e8a7837b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.3 Initialize with true values (5 points)\n",
    "Initialize the three classes with the true values of the parameters and see what happens. Report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a48f788e286458ef0f776865a3bcd58b",
     "grade": true,
     "grade_id": "cell-aa5d6b9f941d985d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dc4adf3081f3bec93f94c3b12b87db9",
     "grade": true,
     "grade_id": "cell-981e44f35a3764b0",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "#### YOUR ANSWER HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd613f41e5d2b7d22b0d5b1e7644a48a",
     "grade": false,
     "grade_id": "cell-19bfd7cf4017ed84",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Variational Auto-Encoder\n",
    "\n",
    "A Variational Auto-Encoder (VAE) is a probabilistic model $p(\\bx, \\bz)$ over observed variables $\\bx$ and latent variables and/or parameters $\\bz$. Here we distinguish the decoder part, $p(\\bx | \\bz) p(\\bz)$ and an encoder part $p(\\bz | \\bx)$ that are both specified with a neural network. A lower bound on the log marginal likelihood $\\log p(\\bx)$ can be obtained by approximately inferring the latent variables z from the observed data x using an encoder distribution $q(\\bz| \\bx)$ that is also specified as a neural network. This lower bound is then optimized to fit the model to the data. \n",
    "\n",
    "The model was introduced by Diederik Kingma (during his PhD at the UVA) and Max Welling in 2013, https://arxiv.org/abs/1312.6114. \n",
    "\n",
    "Since it is such an important model there are plenty of well written tutorials that should help you with the assignment. E.g: https://jaan.io/what-is-variational-autoencoder-vae-tutorial/.\n",
    "\n",
    "In the following, we will make heavily use of the torch module, https://pytorch.org/docs/stable/index.html. Most of the time replacing `np.` with `torch.` will do the trick, e.g. `np.sum` becomes `torch.sum` and `np.log` becomes `torch.log`. In addition, we will use `torch.FloatTensor()` as an equivalent to `np.array()`. In order to train our VAE efficiently we will make use of batching. The number of data points in a batch will become the first dimension of our data tensor, e.g. A batch of 128 MNIST images has the dimensions [128, 1, 28, 28]. To check check the dimensions of a tensor you can call `.size()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92bd337f41c3f94777f47376c7149ca7",
     "grade": false,
     "grade_id": "cell-bcbe35b20c1007d3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Loss function\n",
    "The objective function (variational lower bound), that we will use to train the VAE, consists of two terms: a log Bernoulli loss (reconstruction loss) and a KullbackLeibler divergence. We implement the two terms separately and combine them in the end.\n",
    "As seen in Part 1: Expectation Maximization, we can use a multivariate Bernoulli distribution to model the likelihood $p(\\bx | \\bz)$ of black and white images. Formally, the variational lower bound is maximized but in PyTorch we are always minimizing therefore we need to calculate the negative log Bernoulli loss and KullbackLeibler divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fb5f70b132e1233983ef89d19998374",
     "grade": false,
     "grade_id": "cell-389d81024af846e5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1.1 Negative Log Bernoulli loss (5 points)\n",
    "The negative log Bernoulli loss is defined as,\n",
    "\n",
    "\\begin{align}\n",
    "loss = - (\\sum_i^D \\bx_i \\log \\hat{\\bx_i} + (1  \\bx_i) \\log(1  \\hat{\\bx_i})).\n",
    "\\end{align}\n",
    "\n",
    "Write a function `log_bernoulli_loss` that takes a D dimensional vector `x`, its reconstruction `x_hat` and returns the negative log Bernoulli loss. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "952435ca03f47ab67a7e88b8306fc9a0",
     "grade": false,
     "grade_id": "cell-1d504606d6f99145",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def log_bernoulli_loss(x_hat, x):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return None #torch.nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd2a490aa694507bd032e86d77fc0087",
     "grade": true,
     "grade_id": "cell-9666dad0b2a9f483",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test test test\n",
    "x_test = torch.FloatTensor([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 0.9, 0.9, 0.9]])\n",
    "x_hat_test = torch.FloatTensor([[0.11, 0.22, 0.33, 0.44], [0.55, 0.66, 0.77, 0.88], [0.99, 0.99, 0.99, 0.99]])\n",
    "\n",
    "assert log_bernoulli_loss(x_hat_test, x_test) > 0.0\n",
    "assert log_bernoulli_loss(x_hat_test, x_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b75b7a531ecc87bce57925c4da464ee",
     "grade": false,
     "grade_id": "cell-b3a7c02dee7aa505",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1.2 Negative KullbackLeibler divergence (10 Points)\n",
    "The variational lower bound (the objective to be maximized) contains a KL term $D_{KL}(q(\\bz)||p(\\bz))$ that can often be calculated analytically. In the VAE we assume $q = N(\\bz, \\mu, \\sigma^2I)$ and $p = N(\\bz, 0, I)$. Solve analytically!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d01a7e7fe2dcf5f1c5fb955b85c8a04a",
     "grade": true,
     "grade_id": "cell-4cab10fd1a636858",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "328115c94a66e8aba0a62896e647c3ba",
     "grade": false,
     "grade_id": "cell-c49899cbf2a49362",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Write a function `KL_loss` that takes two J dimensional vectors `mu` and `logvar` and returns the negative KullbackLeibler divergence. Where `logvar` is $\\log(\\sigma^2)$. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33b14b79372dd0235d67bb66921cd3e0",
     "grade": false,
     "grade_id": "cell-125b41878005206b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def KL_loss(mu, logvar):\n",
    "    # YOUR CODE HERE\n",
    "    return - 0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf72e196d2b60827e8e940681ac50a07",
     "grade": true,
     "grade_id": "cell-ba714bbe270a3f39",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test test test\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "assert KL_loss(mu_test, logvar_test) > 0.0\n",
    "assert KL_loss(mu_test, logvar_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65335a588baac26bc48dd6c4d275fdca",
     "grade": false,
     "grade_id": "cell-18cb3f8031edec23",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1.3 Putting the losses together (5 points)\n",
    "Write a function `loss_function` that takes a D dimensional vector `x`, its reconstruction `x_hat`, two J dimensional vectors `mu` and `logvar` and returns the final loss. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6ecb5b60b2c8d7b90070ed59320ee70",
     "grade": false,
     "grade_id": "cell-d2d18781683f1302",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(x_hat, x, mu, logvar):\n",
    "    # YOUR CODE HERE\n",
    "    return KL_loss(mu, logvar) + log_bernoulli_loss(x_hat_test, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "816e9508408bfcb2c7332b508d505081",
     "grade": true,
     "grade_id": "cell-57747988d29bbb5d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x_test = torch.FloatTensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "x_hat_test = torch.FloatTensor([[0.11, 0.22, 0.33], [0.44, 0.55, 0.66], [0.77, 0.88, 0.99]])\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "assert loss_function(x_hat_test, x_test, mu_test, logvar_test) > 0.0\n",
    "assert loss_function(x_hat_test, x_test, mu_test, logvar_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4506e06ed44a0535140582277a528ba4",
     "grade": false,
     "grade_id": "cell-9e3ba708967fe918",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.2 The model\n",
    "Below you see a data structure for the VAE. The modell itself consists of two main parts the encoder (images $\\bx$ to latent variables $\\bz$) and the decoder (latent variables $\\bz$ to images $\\bx$). The encoder is using 3 fully-connected layers, whereas the decoder is using fully-connected layers. Right now the data structure is quite empty, step by step will update its functionality. For test purposes we will initialize a VAE for you. After the data structure is completed you will do the hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31eccf2f6600764e28eb4bc6c5634e49",
     "grade": false,
     "grade_id": "cell-e7d9dafee18f28a1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, fc1_dims, fc21_dims, fc22_dims, fc3_dims, fc4_dims):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(*fc1_dims)\n",
    "        self.fc21 = nn.Linear(*fc21_dims)\n",
    "        self.fc22 = nn.Linear(*fc22_dims)\n",
    "        self.fc3 = nn.Linear(*fc3_dims)\n",
    "        self.fc4 = nn.Linear(*fc4_dims)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def decode(self, z):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "VAE_test = VAE(fc1_dims=(784, 4), fc21_dims=(4, 2), fc22_dims=(4, 2), fc3_dims=(2, 4), fc4_dims=(4, 784))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a2243397998b4f55c25dfd734f3e7e0",
     "grade": false,
     "grade_id": "cell-c4f9e841b8972a43",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.3 Encoding (10 points)\n",
    "Write a function `encode` that gets a vector `x` with 784 elements (flattened MNIST image) and returns `mu` and `logvar`. Your function should use three fully-connected layers (`self.fc1()`, `self.fc21()`, `self.fc22()`). First, you should use `self.fc1()` to embed `x`. Second, you should use `self.fc21()` and `self.fc22()` on the embedding of `x` to compute `mu` and `logvar` respectively. PyTorch comes with a variety of activation functions, the most common calls are `F.relu()`, `F.sigmoid()`, `F.tanh()`. Make sure that your function works for batches of arbitrary size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "628bcd88c611cf01e70f77854600199b",
     "grade": false,
     "grade_id": "cell-93cb75b98ae76569",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def encode(self, x):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "370d930fa9f10f1d3a451f3805c04d88",
     "grade": true,
     "grade_id": "cell-9648960b73337a70",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test, test, test\n",
    "VAE.encode = encode\n",
    "\n",
    "x_test = torch.ones((5,784))\n",
    "mu_test, logvar_test = VAE_test.encode(x_test)\n",
    "\n",
    "assert np.allclose(mu_test.size(), [5, 2])\n",
    "assert np.allclose(logvar_test.size(), [5, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f597cc2b5ef941af282d7162297f865",
     "grade": false,
     "grade_id": "cell-581b4ed1996be868",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Reparameterization (10 points)\n",
    "One of the major question that the VAE is answering, is 'how to take derivatives with respect to the parameters of a stochastic variable?', i.e. if we are given $\\bz$ that is drawn from a distribution $q(\\bz|\\bx)$, and we want to take derivatives. This step is necessary to be able to use gradient-based optimization algorithms like SGD.\n",
    "For some distributions, it is possible to reparameterize samples in a clever way, such that the stochasticity is independent of the parameters. We want our samples to deterministically depend on the parameters of the distribution. For example, in a normally-distributed variable with mean $\\mu$ and standard deviation $\\sigma$, we can sample from it like this:\n",
    "\n",
    "\\begin{align}\n",
    "\\bz = \\mu + \\sigma \\odot \\epsilon,\n",
    "\\end{align}\n",
    "\n",
    "where $\\odot$ is the element-wise multiplication and $\\epsilon$ is sampled from $N(0, I)$.\n",
    "\n",
    "\n",
    "Write a function `reparameterize` that takes two J dimensional vectors `mu` and `logvar`. It should return $\\bz = \\mu + \\sigma \\odot \\epsilon$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6331cb5dd23aaacbcf1a52cfecb1afaa",
     "grade": false,
     "grade_id": "cell-679aea8b2adf7ec4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def reparameterize(self, mu, logvar):\n",
    "    # YOUR CODE HERE\n",
    "    epsilon = torch.randn_like(mu)\n",
    "    return mu + torch.exp(0.5*logvar)*epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38d4e047717ab334b262c8c177f0a420",
     "grade": true,
     "grade_id": "cell-fdd7b27a3d17f84e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test, test, test\n",
    "VAE.reparameterize = reparameterize\n",
    "VAE_test.train()\n",
    "\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "z_test = VAE_test.reparameterize(mu_test, logvar_test)\n",
    "\n",
    "assert np.allclose(z_test.size(), [3, 2])\n",
    "assert z_test[0][0] < 5.0\n",
    "assert z_test[0][0] > -5.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9241ab0eaf8366c37ad57072ce66f095",
     "grade": false,
     "grade_id": "cell-0be851f9f7f0a93e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Decoding (10 points)\n",
    "Write a function `decode` that gets a vector `z` with J elements and returns a vector `x_hat` with 784 elements (flattened MNIST image). Your function should use two fully-connected layers (`self.fc3()`, `self.fc4()`). PyTorch comes with a variety of activation functions, the most common calls are `F.relu()`, `F.sigmoid()`, `F.tanh()`. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8e833cfd7c54a9b67a38056d5d6cab8",
     "grade": false,
     "grade_id": "cell-bf92bb3878275a41",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def decode(self, z):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return x_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7732293fd7d971fcf255496e8c68638d",
     "grade": true,
     "grade_id": "cell-4abb91cb9e80af5d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test test test\n",
    "VAE.decode = decode\n",
    "\n",
    "z_test = torch.ones((5,2))\n",
    "x_hat_test = VAE_test.decode(z_test)\n",
    "\n",
    "assert np.allclose(x_hat_test.size(), [5, 784])\n",
    "assert (x_hat_test <= 1).all()\n",
    "assert (x_hat_test >= 0).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2e113d1f45398b2a1399c336526e755",
     "grade": false,
     "grade_id": "cell-97511fbc4f5b469b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.6 Forward pass (10)\n",
    "To complete the data structure you have to define a forward pass through the VAE. A single forward pass consists of the encoding of an MNIST image $\\bx$ into latent space $\\bz$, the reparameterization of $\\bz$ and the decoding of $\\bz$ into an image $\\bx$.\n",
    "\n",
    "Write a function `forward` that gets a a vector `x` with 784 elements (flattened MNIST image) and returns a vector `x_hat` with 784 elements (flattened MNIST image), `mu` and `logvar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7433c4631dd01c07a5fe287e55ae13",
     "grade": false,
     "grade_id": "cell-26bb463b9f98ebd5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = x.view(-1, 784)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return x_hat, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e7e495f40465c162512e9873c360b25",
     "grade": true,
     "grade_id": "cell-347e5fba3d02754b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test test test \n",
    "VAE.forward = forward\n",
    "\n",
    "x_test = torch.ones((5,784))\n",
    "x_hat_test, mu_test, logvar_test = VAE_test.forward(x_test)\n",
    "\n",
    "assert np.allclose(x_hat_test.size(), [5, 784])\n",
    "assert np.allclose(mu_test.size(), [5, 2])\n",
    "assert np.allclose(logvar_test.size(), [5, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a114a6fd781fb949b887e6a028e07946",
     "grade": false,
     "grade_id": "cell-62c89e4d3b253671",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.7 Training (15)\n",
    "We will now train the VAE using an optimizer called Adam, https://arxiv.org/abs/1412.6980. The code to train a model in PyTorch is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3b6bb965fb48229c63cacda48baea65",
     "grade": false,
     "grade_id": "cell-be75f61b09f3b9b6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train(epoch, train_loader, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data.view(-1, 784), mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48ca730dbef06a668f4dfdb24888f265",
     "grade": false,
     "grade_id": "cell-da1b063b7de850b9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's train. You have to choose the hyperparameters. Make sure your loss is going down in a reasonable amount of epochs (around 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "846430258fb80f50b161135448726520",
     "grade": false,
     "grade_id": "cell-d4d4408d397f6967",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# fc1_dims = (?,?)\n",
    "# fc21_dims =\n",
    "# fc22_dims =\n",
    "# fc3_dims =\n",
    "# fc4_dims =\n",
    "# lr =\n",
    "# batch_size =\n",
    "# epochs =\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b93390f399b743276bc25e67493344f2",
     "grade": true,
     "grade_id": "cell-ca352d8389c1809a",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains a hidden test, please don't delete it, thx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20719070ed85964de9722acc3456a515",
     "grade": false,
     "grade_id": "cell-5c77370db7cec9f2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Run the box below to train the model using the hyperparameters you entered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38306be3638e85812bd5b2a052fcc0a4",
     "grade": false,
     "grade_id": "cell-5712d42de1068398",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "# Load data\n",
    "train_data = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=batch_size, shuffle=True, **{})\n",
    "\n",
    "# Init model\n",
    "VAE_MNIST = VAE(fc1_dims=fc1_dims, fc21_dims=fc21_dims, fc22_dims=fc22_dims, fc3_dims=fc3_dims, fc4_dims=fc4_dims)\n",
    "\n",
    "# Init optimizer\n",
    "optimizer = optim.Adam(VAE_MNIST.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, train_loader, VAE_MNIST, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2f8fcc9384e30cb154cf931f223898b",
     "grade": false,
     "grade_id": "cell-bd07c058c661b9c6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Run the box below to check if the model you trained above is able to correctly reconstruct images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80d198e03b1287741d761a12e38dcf73",
     "grade": false,
     "grade_id": "cell-df03d717307a6863",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Let's check if the reconstructions make sense\n",
    "# Set model to test mode\n",
    "VAE_MNIST.eval()\n",
    "    \n",
    "# Reconstructed\n",
    "train_data_plot = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "\n",
    "train_loader_plot = torch.utils.data.DataLoader(train_data_plot,\n",
    "                                           batch_size=1, shuffle=False, **{})\n",
    "\n",
    "for batch_idx, (data, _) in enumerate(train_loader_plot):\n",
    "    x_hat, mu, logvar = VAE_MNIST(data)\n",
    "    plt.imshow(x_hat.view(1,28,28).squeeze().data.numpy(), cmap='gray')\n",
    "    plt.title('%i' % train_data.train_labels[batch_idx])\n",
    "    plt.show()\n",
    "    if batch_idx == 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f559122b150f5f1228d6b66b62f462c",
     "grade": false,
     "grade_id": "cell-76649d51fdf133dc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.8 Visualize latent space (20 points)\n",
    "Now, implement the auto-encoder now with a 2-dimensional latent space, and train again over the MNIST data. Make a visualization of the learned manifold by using a linearly spaced coordinate grid as input for the latent space, as seen in  https://arxiv.org/abs/1312.6114 Figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c879ffdb0d355349d7144a33d16ca93a",
     "grade": true,
     "grade_id": "cell-4a0af6d08d055bee",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "def plot_manifold(model, n_manifold=19):\n",
    "    # Set the grid space\n",
    "    z1 = torch.from_numpy(norm.ppf(np.linspace(0.01, 0.99, n_manifold))).float()\n",
    "    z2 = torch.from_numpy(norm.ppf(np.linspace(0.01, 0.99, n_manifold))).float()\n",
    "    # Get the grid\n",
    "    manifold_grid = torch.stack(torch.meshgrid(z1, z2))\n",
    "    manifold_grid = manifold_grid.permute(2, 1, 0)\n",
    "    # Stack tensos in form (batch_size x z_dim)\n",
    "    manifold_grid = manifold_grid.contiguous().view(-1, ARGS.zdim)\n",
    "    # Pass it though the decoder to generate images\n",
    "    manifold_imgs = model.module.decoder(manifold_grid)\n",
    "    # torch tensor to numpy\n",
    "    image = manifold_imgs.data.view(-1, 1, 28, 28).numpy()\n",
    "    image = np.squeeze(image[0])\n",
    "    # Plot the manifold\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 20))\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title('VAE MNIST Manifold', fontsize=16)\n",
    "    ax.axis('off')\n",
    "\n",
    "plot_manifold(VAE_MNIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9eb1684d646eea84a25638d184bfbda",
     "grade": false,
     "grade_id": "cell-dc5e1247a1e21009",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.8 Amortized inference (10 points)\n",
    "What is amortized inference? Where in the code of Part 2 is it used? What is the benefit of using it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "364ed922da59070f319d0bdfb0e41d92",
     "grade": true,
     "grade_id": "cell-6f7808a9b0098dbf",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
